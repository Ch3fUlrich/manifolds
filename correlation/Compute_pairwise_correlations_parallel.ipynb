{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f98c6b4-4a90-4f64-adae-4ce2b75e4d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/code/donatolab/manifolds/utils/animal_database/animal_database.py:11: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import nest_asyncio\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# \n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "# add root directory to be able to import packages\n",
    "# todo: make all packages installable so they can be called/imported by environment\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from utils.calcium import calcium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28da3655-1a7f-43c0-ba3b-f42276c20e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sessions:  ['20220317', '20220323', '20220325', '20220219', '20220314', '20220315', '20220316', '20220313', '20220224', '20220307', '20220330', '20220223', '20220227', '20220305', '20220304', '20220311', '20220222', '20220321', '20220310', '20220322', '20220324', '20220216', '20220226', '20220320', '20220217', '20220303', '20220308', '20220220', '20220221', '20220328', '20220302', '20220215', '20220225', '20220329', '20220319', '20220309', '20220326', '20220327', '20220312', '20220318', '20220401', '20220306', '20220228', '20220218', '20220331']\n",
      "processing:  20220317\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220323\n",
      "... errror loading :  20220323\n",
      "processing:  20220325\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220219\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220314\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220315\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220316\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220313\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220224\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220307\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220330\n",
      "... errror loading :  20220330\n",
      "processing:  20220223\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220227\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220305\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220304\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220311\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220222\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220321\n",
      "... errror loading :  20220321\n",
      "processing:  20220310\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220322\n",
      "... errror loading :  20220322\n",
      "processing:  20220324\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220216\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220226\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220320\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220217\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220303\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220308\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220220\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220221\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220328\n",
      "... errror loading :  20220328\n",
      "processing:  20220302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/code/donatolab/manifolds/utils/calcium/calcium.py:251: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cumsum = cumsum/np.max(cumsum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... errror loading :  20220302\n",
      "processing:  20220215\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220225\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220329\n",
      "... errror loading :  20220329\n",
      "processing:  20220319\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220309\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/code/donatolab/manifolds/utils/calcium/calcium.py:251: RuntimeWarning: invalid value encountered in true_divide\n",
      "  cumsum = cumsum/np.max(cumsum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... errror loading :  20220326\n",
      "processing:  20220327\n",
      "... errror loading :  20220327\n",
      "processing:  20220312\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220318\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220401\n",
      "... errror loading :  20220401\n",
      "processing:  20220306\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220228\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220218\n",
      "check #1: \n",
      "check #2: \n",
      "check #3: \n",
      "processing:  20220331\n",
      "... errror loading :  20220331\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "################# Load data ################\n",
    "############################################\n",
    "\n",
    "#\n",
    "def get_sessions_from_directory_listing(root_dir,\n",
    "                                       animal_id):\n",
    "    \n",
    "    sessions = os.listdir(root_dir+animal_id)\n",
    "    print (\"sessions: \", sessions)\n",
    "    \n",
    "    return sessions\n",
    "    \n",
    "#\n",
    "root_dir = '/media/cat/4TB1/donato/'\n",
    "animal_id = 'DON-009192'\n",
    "dir_ = '/002P-F/tif/'\n",
    "\n",
    "sessions = get_sessions_from_directory_listing(root_dir,\n",
    "                                              animal_id)\n",
    "\n",
    "#\n",
    "for session in sessions:\n",
    "    #\n",
    "    try: \n",
    "        print (\"processing: \", session)\n",
    "        c = calcium.Calcium()\n",
    "        c.root_dir = root_dir\n",
    "        c.data_dir = os.path.join(root_dir, animal_id, session+dir_, 'suite2p','plane0')\n",
    "        c.animal_id = animal_id\n",
    "        c.session = session\n",
    "        c.detrend_model_order = 1\n",
    "        c.load_suite2p()\n",
    "        c.save_python = True\n",
    "        c.save_matlab = False\n",
    "\n",
    "        # \n",
    "        c.load_binarization()\n",
    "        binarization_method = 'upphase'\n",
    "        if binarization_method=='onphase':\n",
    "            traces = c.F_onphase_bin\n",
    "        elif binarization_method=='upphase':\n",
    "            traces = c.F_upphase_bin\n",
    "        else:\n",
    "            print (\"METHOD NOT FOUND\")\n",
    "\n",
    "        #print (\"binarized data: \", traces.shape)\n",
    "\n",
    "        ###################################################################\n",
    "        ########## cleanup cells + compute pairwise correlations ##########\n",
    "        ###################################################################\n",
    "        c.load_footprints()\n",
    "        c.deduplication_method = 'overlap'      # 'overlap'; 'centre_distance'\n",
    "        c.corr_min_distance = 8                 # min distance for centre_distance method - NOT USED HERE\n",
    "        c.corr_max_percent_overlap = 0.25       # max overlap for overlap method\n",
    "        c.corr_threshold = 0.3                  # max correlation allowed for high overlap\n",
    "\n",
    "        #  \n",
    "        c.corr_delete_method = 'lowest_snr' #'highest_connected', lowest_snr'\n",
    "        c.recompute_deduplication = False\n",
    "\n",
    "        c.remove_duplicate_neurons()\n",
    "    except:\n",
    "        print (\"... errror loading : \", session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a564f3f-f40e-4457-85da-1ba403350305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/cat/4TB1/donato/tests/DON-010473_20220514_002P-F_S1-S2-ACQ.mesc ['S1', 'S2']\n"
     ]
    }
   ],
   "source": [
    "def get_sessions_from_filename(fname):\n",
    "    \n",
    "    fname = fname.replace(\"-\",\"_\")\n",
    "    \n",
    "    idx1 = fname.find(\"002P_F\")+7\n",
    "    idx2 = fname.find('.mesc')\n",
    "    \n",
    "    sessions = fname[idx1:idx2].replace(\"-\",\"_\").split(\"_\")\n",
    "    \n",
    "    try:\n",
    "        sessions.remove(\"ACQ\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return sessions\n",
    "\n",
    "\n",
    "def get_sessions_from_filename2(fname):\n",
    "\n",
    "    sessions = []\n",
    "    for k in range(1,20,1):\n",
    "        temp = \"S\"+str(k)\n",
    "        if temp in fname:\n",
    "            sessions.append(temp)\n",
    "\n",
    "    return sessions\n",
    "\n",
    "\n",
    "\n",
    "def get_sessions_for_mesc_and_raw_filenames_from_directory(folder):\n",
    "    \n",
    "    fs = []\n",
    "    ss = []\n",
    "    \n",
    "    # look for .mesc files\n",
    "    extensions = '.mesc'\n",
    "    \n",
    "    matches = []\n",
    "    for root, dirnames, filenames in os.walk(folder):\n",
    "        #print (root, dirnames, filenames)\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(extensions):\n",
    "                matches.append(os.path.join(root, filename))\n",
    "                \n",
    "    for match in matches:\n",
    "        sessions = get_sessions_from_filename2(match)\n",
    "        fs.append(match)\n",
    "        ss.append(sessions)\n",
    "        #print (match, sessions)\n",
    "        \n",
    "    # look for .raw files\n",
    "    extensions = '.raw'\n",
    "    matches = []\n",
    "    for root, dirnames, filenames in os.walk(folder):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith(extensions):\n",
    "                matches.append(os.path.join(root, filename))\n",
    "    \n",
    "    for match in matches:\n",
    "        fs.append(match)\n",
    "        ss.append([])           \n",
    "\n",
    "        \n",
    "    return fs, ss\n",
    "\n",
    "folder = '/media/cat/4TB1/donato/tests'\n",
    "fnames, sessions = get_sessions_for_mesc_and_raw_filenames_from_directory(folder)\n",
    "for k in range(len(fnames)):\n",
    "    print (fnames[k], sessions[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18fe47cf-c643-42db-ace6-ed10c28411ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session loaded:  MUnit_0\n",
      "session loaded:  MUnit_1\n"
     ]
    }
   ],
   "source": [
    "def convert_mesc_sessions_to_concatenated_tiff(fname,\n",
    "                                               sessions_in):\n",
    "\n",
    "    fname_out = fname.replace('.mesc','.tif')\n",
    "\n",
    "    if os.path.exists(fname_out):\n",
    "        print (\".mesc -> .tiff file already done... skipping conversion...\")\n",
    "        return fname_out\n",
    "\n",
    "    # sessions_in = sessions_in.replace(\" \", \"\").split (\",\")\n",
    "\n",
    "    #\n",
    "    sess_list = []\n",
    "    for session in sessions_in:\n",
    "        temp = session.replace(\"S\",'')\n",
    "        temp = 'MUnit_'+str(int(temp)-1)\n",
    "        print (\"session loaded: \", temp)\n",
    "        sess_list.append(temp)\n",
    "    #\n",
    "    \n",
    "    \n",
    "\n",
    "#fname = fnames[0]\n",
    "#sessions_in = sessions[0]\n",
    "\n",
    "convert_mesc_sessions_to_concatenated_tiff(fname, sessions_in)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb362cf-ecb3-4b26-9eb5-5560a5030631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fname:  /media/cat/4TB1/donato/DON-009192/DON-009192_20220322_002P-F_S1-S2-S3-S4.mesc\n",
      "sessions;  <KeysViewHDF5 ['MSession_0']>\n",
      "processing:  MSession_0\n",
      "Munits:  ['MUnit_0', 'MUnit_1', 'MUnit_2', 'MUnit_3', 'MUnit_4']\n",
      "    data loaded size:  (27874, 512, 512)\n",
      "    data loaded size:  (27874, 512, 512)\n",
      "    data loaded size:  (27874, 512, 512)\n",
      "    data loaded size:  (27874, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# TEST CONTENT OF .mesc files\n",
    "import h5py\n",
    "def get_data(fname,\n",
    "             unit_ids):\n",
    "\n",
    "    data = []\n",
    "    with h5py.File(fname, 'r') as file:\n",
    "\n",
    "        sessions_in = file.keys()\n",
    "        print (\"sessions; \", sessions_in)\n",
    "                    #\n",
    "        for sess in sessions_in:\n",
    "            print (\"processing: \", sess)\n",
    "\n",
    "            units = file[sess].keys()\n",
    "            \n",
    "            munits = []\n",
    "            for unit in units:\n",
    "                munits.append(unit)\n",
    "                \n",
    "            print (\"Munits: \", munits)\n",
    "            \n",
    "            for unit_id in unit_ids:\n",
    "                \n",
    "                temp = file['MSession_0'][munits[unit_id]]['Channel_0'][()]\n",
    "                print (\"    data loaded size: \", temp.shape)\n",
    "                data.append(temp)\n",
    "                \n",
    "    data = np.vstack(data)\n",
    "    print(data.shape)\n",
    "\n",
    "\n",
    "fname = '/media/cat/4TB1/donato/DON-009192/DON-009192_20220401_002P-F_S1-S2.mesc'\n",
    "#fname = '/media/cat/4TB1/donato/DON-009192/DON-010473_20220510_002P-F_S1-ACQ.mesc'\n",
    "#fname = '/media/cat/4TB1/donato/DON-009192/DON-009192_20220322_002P-F_S1-S2-S3-S4.mesc'\n",
    "fname = '/media/cat/4TB1/donato/DON-009192/DON-010477_20220511_002P-F_S1-S2-ACQ.mesc'\n",
    "fname = '/media/cat/4TB1/donato/DON-009192/DON-009191_20220318_002P-F_S1.mesc'\n",
    "fname = '/media/cat/4TB1/donato/DON-009192/DON-009191_20220311_002P-F_S1-S2.mesc'\n",
    "fname = '/media/cat/4TB1/donato/DON-009192/DON-009192_20220322_002P-F_S1-S2-S3-S4.mesc'\n",
    "\n",
    "\n",
    "print (\"fname: \", fname)\n",
    "unit_ids = [0,1,2,3]\n",
    "get_data(fname, unit_ids)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b0502be-0c86-43f0-93a4-588851fd8ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/cat/4TB1/donato/DON-009192/DON-010473_20220510_002P-F_S1-ACQ.mesc\n",
      "sessions;  <KeysViewHDF5 ['MSession_0']>\n",
      "processing:  MSession_0\n",
      "<KeysViewHDF5 ['MUnit_0']>\n"
     ]
    }
   ],
   "source": [
    "fname = '/media/cat/4TB1/donato/DON-009192/DON-010473_20220510_002P-F_S1-ACQ.mesc'\n",
    "print (fname)\n",
    "get_data(fname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d5780-d0cc-4c94-a0b8-cc51fd3a6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mesc_sessions_to_concatenated_tiff(fname,\n",
    "                                               sessions_in):\n",
    "\n",
    "    fname_out = fname.replace('.mesc','.tif')\n",
    "\n",
    "    if os.path.exists(fname_out):\n",
    "        print (\".mesc -> .tiff file already done... skipping conversion...\")\n",
    "        return fname_out\n",
    "\n",
    "    # sessions_in = sessions_in.replace(\" \", \"\").split (\",\")\n",
    "\n",
    "    # #\n",
    "    # sess_list = []\n",
    "    # for session in sessions_in:\n",
    "    #     temp = session.replace(\"S\",'')\n",
    "    #     temp = 'MUnit_'+str(int(temp)-1)\n",
    "    #     print (\"session loaded: \", temp)\n",
    "    #     sess_list.append(temp)\n",
    "    #\n",
    "    data = []\n",
    "    with h5py.File(fname, 'r') as file:\n",
    "                #\n",
    "        for sess in sess_list:\n",
    "            print (\"processing: \", sess)\n",
    "            temp = file['MSession_0'][sess]['Channel_0'][()]\n",
    "            print (\"    data loaded size: \", temp.shape)\n",
    "            data.append(temp)\n",
    "\n",
    "    data = np.vstack(data)\n",
    "    print(data.shape)\n",
    "\n",
    "    #\n",
    "    tifffile.imwrite(fname_out, data)\n",
    "\n",
    "    return fname_out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
