{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f98c6b4-4a90-4f64-adae-4ce2b75e4d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(180000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-e4476ecac24a>:12: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/.conda/envs/donato/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import nest_asyncio\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# \n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "# add root directory to be able to import packages\n",
    "# todo: make all packages installable so they can be called/imported by environment\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from utils.calcium import calcium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28da3655-1a7f-43c0-ba3b-f42276c20e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  DON-002865\n",
      "sessions:  ['DON-002865_20210210', 'DON-002865_202102114', 'DON-002865_202102115', 'DON-002865_202102113', 'DON-002865_202102119', 'DON-002865_20210211', 'DON-002865_202102116', 'DON-002865_202102117', 'DON-002865_202102118', 'DON-002865_202102112']\n",
      "\n",
      "\n",
      "\n",
      "processing:  DON-002865_20210210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "low pass filter: 100%|██████████| 1064/1064 [00:00<00:00, 1565.40it/s]\n",
      "model filter: remove bleaching or trends: 100%|██████████| 1064/1064 [00:08<00:00, 122.01it/s]\n",
      "1071it [00:07, 151.41it/s]                         \n",
      "binarizing continuous traces filtered fluorescence onphase: 100%|██████████| 1064/1064 [00:02<00:00, 516.25it/s]\n",
      "binarizing continuous traces filtered fluorescence upphase: 100%|██████████| 1064/1064 [00:15<00:00, 69.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...saving data...\n",
      "   Queiscent periods (seconds):  87.73333333333333\n",
      "   Running periods (seconds):  2757.4\n",
      "... computing pairwise pearson correlation ...\n",
      " RASTERS IN:  (1064, 86186)\n",
      " BINNING WINDOW:  30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1064 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "################# Load data ################\n",
    "############################################\n",
    "\n",
    "#turn off plotting or multiprocessing will crash\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "#\n",
    "def get_sessions_from_directory_listing(root_dir,\n",
    "                                       animal_id):\n",
    "    \n",
    "    sessions = os.listdir(root_dir+animal_id)\n",
    "    print (\"sessions: \", sessions)\n",
    "    \n",
    "    return sessions\n",
    "    \n",
    "#\n",
    "animal_ids = [\n",
    "    \n",
    "    'DON-002865',\n",
    "    'DON-003165',\n",
    "    'DON-003343',\n",
    "            \n",
    "    'DON-006084',\n",
    "    'DON-006085',\n",
    "    'DON-006087',\n",
    "    \n",
    "\n",
    "#     'DON-008497',\n",
    "#     'DON-008498',\n",
    "#     'DON-008499',\n",
    "    \n",
    "    # 'DON-009191',\n",
    "    # 'DON-009192',\n",
    "    # 'DON-010473',\n",
    "    # 'DON-010477',\n",
    "    \n",
    "\n",
    "       \n",
    "    \n",
    "    \n",
    "]\n",
    "              \n",
    "############################################\n",
    "############################################\n",
    "############################################\n",
    "root_dir = '/media/cat/4TB/donato/'\n",
    "dir_ = '/002P-F/tif/'\n",
    "\n",
    "#\n",
    "for animal_id in animal_ids:\n",
    "\n",
    "    #\n",
    "    print (\"Processing: \", animal_id)\n",
    "\n",
    "    #\n",
    "    sessions = get_sessions_from_directory_listing(root_dir,\n",
    "                                                  animal_id)\n",
    "\n",
    "    #\n",
    "    for session in sessions:\n",
    "        #\n",
    "        fname_check  =  os.path.join(root_dir, \n",
    "                                     animal_id, \n",
    "                                     session+dir_, 'suite2p','plane0',\n",
    "                                     'goodcell_correlations_array_post_deduplication_filtered.npy'\n",
    "                                      )\n",
    "\n",
    "        #\n",
    "        #if os.path.exists(fname_check):\n",
    "        #   continue\n",
    "\n",
    "        #\n",
    "        #try: \n",
    "        try:\n",
    "            #\n",
    "            print ('')\n",
    "            print ('')\n",
    "            print ('')\n",
    "            print (\"processing: \", session)\n",
    "\n",
    "            #if session != '20220302':\n",
    "            #    continue\n",
    "\n",
    "            c = calcium.Calcium()\n",
    "            c.root_dir = root_dir\n",
    "            c.data_dir = os.path.join(root_dir, animal_id, session+dir_, 'suite2p','plane0')\n",
    "            c.animal_id = animal_id\n",
    "            c.session = session\n",
    "            c.detrend_model_order = 1\n",
    "            c.n_cores = 26\n",
    "            \n",
    "            #\n",
    "            c.load_suite2p()           #note: this already deletes the non-trusted suite2p cells\n",
    "            c.save_python = True\n",
    "            c.save_matlab = False\n",
    "\n",
    "            # \n",
    "            c.min_width_event_onphase = 30\n",
    "            c.min_width_event_upphase = 10\n",
    "            c.recompute_binarization = True\n",
    "\n",
    "            # not used currently\n",
    "            c.dff_min = 0.02   #this is the final threshold required by putative spikes\n",
    "            c.percentile_threshold = 0.999999\n",
    "            c.use_upphase = True\n",
    "\n",
    "            #\n",
    "            c.show_plots =False\n",
    "            c.save_plots = True\n",
    "            c.remove_ends = False                     # delete the first and last x seconds in case [ca] imaging had issues\n",
    "            c.detrend_filter_threshold = 0.001\n",
    "            c.mode_window = 30*60  # None: compute mode on entire time; Value: sliding window based - baseline detection # of frames to use to compute mode\n",
    "\n",
    "            #\n",
    "            c.load_binarization()   \n",
    "            c.save_sample_traces()\n",
    "            c.show_rasters(save_image=True)\n",
    "\n",
    "            #\n",
    "            binarization_method = 'upphase'\n",
    "            if binarization_method=='onphase':\n",
    "                traces = c.F_onphase_bin\n",
    "            elif binarization_method=='upphase':\n",
    "                traces = c.F_upphase_bin\n",
    "            else:\n",
    "                print (\"METHOD NOT FOUND\")\n",
    "\n",
    "            \n",
    "            ###################################################################\n",
    "            ########## cleanup cells + compute pairwise correlations ##########\n",
    "            ###################################################################\n",
    "            #c.zscore = True                     # here we compute correlations based on N shuffles of the data and zscore\n",
    "            for z in [[False,False],[True, False],[False,True]]:\n",
    "                ###################################################################\n",
    "                c.subselect_moving_only = z[0]\n",
    "                c.subselect_quiescent_only = z[0]\n",
    "                #c.subselect_moving_only = False\n",
    "                #c.subselect_quiescent_only = False\n",
    "                c.corr_parallel_flag = True\n",
    "                c.zscore = True                     # here we compute correlations based on N shuffles of the data and zscore\n",
    "                                                    # otherwise we save the raw correlation also\n",
    "                c.n_tests_zscore = 1000\n",
    "\n",
    "                #\n",
    "                c.correlation_datatype = 'upphase'      # filtered vs. upphase\n",
    "\n",
    "                # \n",
    "                c.n_cores = 32\n",
    "                c.recompute_correlation = False\n",
    "                c.binning_window = 30        # binning window in frames\n",
    "                c.subsample = 1              # subsample traces by this factor\n",
    "                c.scale_by_DFF = True        # scale traces by DFF\n",
    "                c.shuffle_data = False       # shuffle traces before computing correlations \n",
    "                c.compute_correlations()\n",
    "\n",
    "                # remove duplicate neurons requires correlation array to be computed first; it uses physical overalp but also correlation threshold\n",
    "\n",
    "                #\n",
    "                c.load_footprints()\n",
    "                c.deduplication_method = 'overlap'      # 'overlap'; 'centre_distance'\n",
    "                c.corr_min_distance = 8                 # min distance for centre_distance method - NOT USED HERE\n",
    "                c.corr_max_percent_overlap = 0.25       # max overlap for overlap method\n",
    "                c.corr_threshold = 0.3                  # max correlation allowed for high overlap\n",
    "                c.zscore_threshold = 3.0                # zscore threshold for high overlap\n",
    "\n",
    "                #  \n",
    "                c.corr_delete_method = 'lowest_snr' #'highest_connected', lowest_snr'\n",
    "                c.recompute_deduplication = True\n",
    "                c.remove_duplicate_neurons()     # this removes duplicate neurons and saves non-duplicate version of correlation array\n",
    "\n",
    "                #\n",
    "                print (\"DONE\")\n",
    "        \n",
    "        #\n",
    "        except:\n",
    "           print (\"... errror loading : \", session, \" \", animal_id)\n",
    "\n",
    "print (\"DONE...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60dd4c97-d18b-482a-a38d-19040213a39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1064, 1064, 2)\n",
      "(922,)\n"
     ]
    }
   ],
   "source": [
    "d = np.load('/media/cat/4TB/donato/DON-002865/DON-002865_20210210/002P-F/tif/suite2p/plane0/allcell_correlation_array_upphase_quiescent.npy')\n",
    "\n",
    "print (d.shape)\n",
    "\n",
    "c = np.load('/media/cat/4TB/donato/DON-002865/DON-002865_20210210/002P-F/tif/suite2p/plane0/good_ids_post_deduplication_upphase_quiescent.npy')\n",
    "print (c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5104402-0657-495f-a088-10a9a1977c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f3370-16b4-4d9a-ab2e-bd6d1c4c4aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee294e9-95e1-49e5-a755-e9c1996d867d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
